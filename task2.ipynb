{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis on IMDb dataset\n",
    "Made By: \n",
    "1. Mohamed Tamer El Masry\n",
    "2. Asmaa Mohamed Noaman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"imdb-dataset/Train.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, grew, up, (, b, ., 1965, ), watching, and,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>[When, I, put, this, movie, in, my, DVD, playe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Why, do, people, who, do, not, know, what, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Even, though, I, have, great, interest, in, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Im, a, die, hard, Dads, Army, fan, and, nothi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0   \n",
       "1  When I put this movie in my DVD player, and sa...      0   \n",
       "2  Why do people who do not know what a particula...      0   \n",
       "3  Even though I have great interest in Biblical ...      0   \n",
       "4  Im a die hard Dads Army fan and nothing will e...      1   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [I, grew, up, (, b, ., 1965, ), watching, and,...  \n",
       "1  [When, I, put, this, movie, in, my, DVD, playe...  \n",
       "2  [Why, do, people, who, do, not, know, what, a,...  \n",
       "3  [Even, though, I, have, great, interest, in, B...  \n",
       "4  [Im, a, die, hard, Dads, Army, fan, and, nothi...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "data['tokenized_text'] = data['text'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, grew, up, (, b, ., 1965, ), watching, and,...</td>\n",
       "      <td>[i, grew, up, (, b, ., 1965, ), watch, and, lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>[When, I, put, this, movie, in, my, DVD, playe...</td>\n",
       "      <td>[when, i, put, this, movi, in, my, dvd, player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Why, do, people, who, do, not, know, what, a,...</td>\n",
       "      <td>[whi, do, peopl, who, do, not, know, what, a, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Even, though, I, have, great, interest, in, B...</td>\n",
       "      <td>[even, though, i, have, great, interest, in, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Im, a, die, hard, Dads, Army, fan, and, nothi...</td>\n",
       "      <td>[im, a, die, hard, dad, armi, fan, and, noth, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0   \n",
       "1  When I put this movie in my DVD player, and sa...      0   \n",
       "2  Why do people who do not know what a particula...      0   \n",
       "3  Even though I have great interest in Biblical ...      0   \n",
       "4  Im a die hard Dads Army fan and nothing will e...      1   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [I, grew, up, (, b, ., 1965, ), watching, and,...   \n",
       "1  [When, I, put, this, movie, in, my, DVD, playe...   \n",
       "2  [Why, do, people, who, do, not, know, what, a,...   \n",
       "3  [Even, though, I, have, great, interest, in, B...   \n",
       "4  [Im, a, die, hard, Dads, Army, fan, and, nothi...   \n",
       "\n",
       "                                        stemmed_text  \n",
       "0  [i, grew, up, (, b, ., 1965, ), watch, and, lo...  \n",
       "1  [when, i, put, this, movi, in, my, dvd, player...  \n",
       "2  [whi, do, peopl, who, do, not, know, what, a, ...  \n",
       "3  [even, though, i, have, great, interest, in, b...  \n",
       "4  [im, a, die, hard, dad, armi, fan, and, noth, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "data['stemmed_text'] = data['tokenized_text'].apply(lambda x : [stemmer.stem(word) for word in x])\n",
    "\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
